<html>
<head>
    <meta charset="UTF-8">
    <title>Speech synthesis demos
    </title>
</head>
<body>

<article>
    <header>
        <h1>Speech synthesis demos
    </header>
</article>
Last updated 1 Jun 2020

<hr>

<div>
<b>Improved Parallel WaveGAN with perceptually weighted spectrogram loss</b>
<br>
<ul>
  <li>Eunwoo Song, Ryuichi Yamamoto, Min-Jae Hwang, Jin-Seob Kim, Ohsung Kwon, Jae-Min Kim</li>
  <li>Demo page: <a href=https://sewplay.github.io/demos/pwsl_wavegan/>https://sewplay.github.io/demos/pwsl_wavegan</a></li>
  <li>Submitted to: <a href=http://www.interspeech2020.org/>INTERSPEECH 2020</a></li>
</ul>
</div>

<hr>

<div>
<b>Neural text-to-speech with a modeling-by-generation excitation vocoder</b>
<br>
<ul>
  <li>Eunwoo Song, Min-Jae Hwang, Ryuichi Yamamoto, Jin-Seob Kim, Ohsung Kwon, Jae-Min Kim</li>
  <li>Demo page: <a href=https://sewplay.github.io/demos/mbg_excitnet/>https://sewplay.github.io/demos/mbg_excitnet</a></li>
  <li>Submitted to: <a href=http://www.interspeech2020.org/>INTERSPEECH 2020</a></li>
</ul>
</div>

<hr>

<div>
<b>Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram</b>
<br>
<ul>
  <li>Authors: Ryuichi Yamamoto, Eunwoo Song, Jae-Min Kim</li>
  <li>Demo page: <a href=https://r9y9.github.io/demos/projects/icassp2020/>https://r9y9.github.io/demos/projects/icassp2020</a></li>
  <li>Published in: <a href=https://2020.ieeeicassp.org/>ICASSP 2020</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/1910.11480/">1910.11480</a></li>
</ul>
</div>

<hr>

<div>
<b>Improving LPCNet-based text-to-speech with linear predictions-structured mixture density network</b>
<br>
<ul>
  <li>Authors: Min-Jae Hwang, Eunwoo Song, Ryuichi Yamamoto, Frank K. Soong, Hong-Goo Kang</li>
  <li>Demo page: <a href=https://min-jae.github.io/icassp2020/>https://min-jae.github.io/icassp2020</a></li>
  <li>Published in: <a href=https://2020.ieeeicassp.org/>ICASSP 2020</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/2001.11686/">2001.11686</a></li>
</ul>
</div>

<hr>

<div>
<b>Probability density distillation with generative adversarial networks for high-quality parallel waveform generation</b>
<br>
<ul>
  <li>Authors: Ryuichi Yamamoto, Eunwoo Song, Jae-Min Kim</li>
  <li>Demo page: <a href=https://r9y9.github.io/demos/projects/interspeech2019/>https://r9y9.github.io/demos/projects/interspeech2019</a></li>
  <li>Published in: <a href=https://www.interspeech2019.org/>INTERSPEECH 2019</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/1904.04472/">1904.04472</a></li>
</ul>
</div>

<hr>

<div>
<b>ExcitNet vocoder: A neural excitation model for parametric speech synthesis systems</b>
<br>
<ul>
  <li>Authors: Eunwoo Song, Kyungguen Byun, Hong-Goo Kang</li>
  <li>Demo page: <a href=https://sewplay.github.io/demos/excitnet/>https://sewplay.github.io/demos/excitnet</a></li>
  <li>Published in: <a href=http://eusipco2019.org/>EUSIPCO 2019</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/1811.04769/">1811.04769</a></li>
</ul>
</div>

<hr>

<div>
<b>Effective parameter estimation methods for an ExcitNet model in generative text-to-speech systems</b>
<br>
<ul>
  <li>Authors: Ohsung Kwon, Eunwoo Song, Jae-Min Kim, Hong-Goo Kang</li>
  <li>Demo page: <a href=https://sewplay.github.io/demos/gst_tacotron2_excitnet/>https://sewplay.github.io/demos/gst_tacotron2_excitnet</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/1905.08486/">1905.08486</a></li>
</ul>
</div>

<hr>

<div>
<b>LP-WaveNet: Linear prediction-based WaveNet speech synthesis</b>
<br>
<ul>
  <li>Authors: Min-Jae Hwang, Frank Soong, Eunwoo Song, Xi Wang, Hyeonjoo Kang, Hong-Goo Kang</li>
  <li>Demo page: <a href=https://min-jae.github.io/eusipco2020/>https://min-jae.github.io/eusipco2020</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/1811.11913/">1811.11913</a></li>
</ul>
</div>
<hr>

<div>
<b>Speaker-adaptive neural vocoders for parametric speech synthesis systems</b>
<br>
<ul>
  <li>Authors: Eunwoo Song, Jinseob Kim, Kyungguen Byun, Hong-Goo Kang</li>
  <li>Demo page: <a href=https://sewplay.github.io/demos/vocoder_adaptation/>https://sewplay.github.io/demos/vocoder_adaptation</a></li>
  <li>Preprinted version: <a href=https://arxiv.org/abs/1811.03311/">1811.03311</a></li>
</ul>
</div>

<hr>

