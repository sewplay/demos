<html>
<head>
    <meta charset="UTF-8">
    <title>Speaker-adaptive neural vocoders for parametric speech synthesis systems
    </title>
    <link rel="shortcut icon" href="img/clova_192x192.png">
    <link rel="icon" href="img/clova_192x192.png">
    <link rel="apple-touch-icon" href="img/clova_192x192.png">
</head>
<body>

<article>
    <header>
        <h1>Speaker-adaptive neural vocoders for parametric speech synthesis systems</h1>
    </header>
</article>

<hr>
<div>
Authors: <b>Eunwoo Song, Jinseob Kim, Kyungguen Byun, Hong-Goo Kang</b>
<br>
Date: 28 Jun 2019 (last updated 17 Mar 2020)
<ul>
  <li>Abstract</li>
    This paper proposes speaker-adaptive neural vocoders for text-to-speech (TTS) systems. 
    Recently proposed WaveNet-based neural vocoding systems successfully generate a time sequence of speech signal with an autoregressive framework.
    However, it remains a challenge to build high-quality speech synthesis systems when the amount of a target speaker's training data is insufficient.
    To generate more natural speech signals with the constraint of limited training data, we propose a speaker adaptation task with an effective variation of neural vocoding models.
    In the proposed method, a speaker-independent training method is applied to capture universal attributes embedded in multiple speakers, and the trained model is then optimized to represent the specific characteristics of the target speaker.
    Experimental results verify that the proposed TTS systems with speaker-adaptive neural vocoders outperform those with traditional source-filter model-based vocoders and those with WaveNet vocoders, trained either speaker-dependently or speaker-independently.
    In particular, our TTS system achieves 3.80 and 3.77 MOS for the Korean male and Korean female speakers, respectively, even though we use only ten minutes' speech corpus for training the model.
    <br>
</ul>
  <center>
  <img src="img/fig1.png">
  </center>
<!--
<ul>
  <br>
  <li>Preprinted version: <a href=http://arxiv.org/abs/1811.03311/">1811.03311</a></li>
</ul>
-->
</div>  
<hr>

<div>
Table of Contents
<ul>
  <li><a href="#c1">Speech analysis and synthesis</a></li>
  <ul>
    <li>Vocoding model: WaveNet vocoder <a href="#c3">[1]</a>, ExcitNet vocoder <a href="#c3">[2]</li>
  </ul>
  <li><a href="#c2">Text-to-speech</a></li>
  <ul>
    <li>Vocoding model: WaveNet vocoder, ExcitNet vocoder</li>
  </ul>
</ul>
</div>
<hr>

<div>
<h2 id="c1">Speech analysis and synthesis</h2>
<ul>
<b>Korean female speaker</b>
<br>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border:none;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}
.tg .tg-8jgo{border-color:#ffffff;text-align:center;vertical-align:top}
.tg .tg-lghr{border-color:#ffffff;text-align:center}
.tg .tg-0a55{background-color:#f0f0f0;border-color:#ffffff;text-align:center;vertical-align:top}
.tg .tg-modu{background-color:#f0f0f0;border-color:#ffffff;text-align:center}
</style>
<table class="tg">
  <tr>
    <th class="tg-modu" colspan="3"><b>RAW</b></th>
  </tr>
  <tr>
    <td class="tg-lghr" colspan="3">
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_RAW.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_RAW.wav">
      </audio>   
      <br><br>
    </td>    
  </tr>  
  <tr>
    <td class="tg-modu" colspan="3"><b>WaveNet vocoder</b></td>
  </tr>
  <tr>
    <td class="tg-lghr">      
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_as_sd_WaveNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_as_sd_WaveNet.wav">
      </audio>
      <br>
      <b>Speaker-dependent</b>
      <br><br>
    </td>
    <td class="tg-lghr">      
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_as_si_WaveNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_as_si_WaveNet.wav">
      </audio>
      <br>
      <b>Speaker-independent</b>
      <br><br>
    <td class="tg-lghr">
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_as_sa_WaveNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_as_sa_WaveNet.wav">
      </audio>
      <br>
      <b>Speaker-adaptive</b>
      <br><br>
    </td>
  </tr>
  <tr>
    <td class="tg-0a55" colspan="3"><b>ExcitNet vocoder</b></td>
  </tr>
  <tr>
    <td class="tg-8jgo">
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_as_sd_ExcitNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_as_sd_ExcitNet.wav">
      </audio>
      <br>
      <b>Speaker-dependent</b>
      <br><br>
    </td>
    <td class="tg-8jgo">
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_as_si_ExcitNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_as_si_ExcitNet.wav">
      </audio>
      <br>
      <b>Speaker-independent</b>
      <br><br>
    </td>
    <td class="tg-8jgo">
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample001_as_sa_ExcitNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/analysis-synthesis/krf/sample002_as_sa_ExcitNet.wav">
      </audio>
      <br>
      <b>Speaker-adaptive</b>
      <br><br>
    </td>
  </tr>
</table>
<br>
</ul>
</div>

<hr>

<div>
<h2 id="c2">Text-to-speech</h2>
<ul>
<b>Korean female speaker</b>
<br>
<table class="tg">
  <tr>
    <th class="tg-modu" colspan="3"><b>RAW</b></th>
  </tr>
  <tr>
    <td class="tg-lghr" colspan="3">
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_RAW.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_RAW.wav">
      </audio>   
      <br><br>
    </td>    
  </tr>  
  <tr>
    <td class="tg-modu" colspan="3"><b>WaveNet vocoder</b></td>
  </tr>
  <tr>
    <td class="tg-lghr">      
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_tts_sd_WaveNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_tts_sd_WaveNet.wav">
      </audio>
      <br>
      <b>Speaker-independent</b>
      <br><br>
    </td>
    <td class="tg-lghr">      
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_tts_si_WaveNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_tts_si_WaveNet.wav">
      </audio>
      <br>
      <b>Speaker-independent</b>
      <br><br>
    <td class="tg-lghr">
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_tts_sa_WaveNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_tts_sa_WaveNet.wav">
      </audio>
      <br>
      <b>Speaker-adaptive</b>
      <br><br>
    </td>
  </tr>
  <tr>
    <td class="tg-0a55" colspan="3"><b>ExcitNet vocoder</b></td>
  </tr>
  <tr>
    <td class="tg-8jgo">
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_tts_sd_ExcitNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_tts_sd_ExcitNet.wav">
      </audio>
      <br>
      <b>Speaker-dependent</b>
      <br><br>
    </td>
    <td class="tg-8jgo">
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_tts_si_ExcitNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_tts_si_ExcitNet.wav">
      </audio>
      <br>
      <b>Speaker-independent</b>
      <br><br>
    </td>
    <td class="tg-8jgo">
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample001_tts_sa_ExcitNet.wav">
      </audio>
      <br>
      <audio controls style="width: 250px;">
      <source src="samples/text-to-speech/krf/sample002_tts_sa_ExcitNet.wav">
      </audio>
      <br>
      <b>Speaker-adaptive</b>
      <br><br>
    </td>
  </tr>
</table>
</ul>
</div>

<hr>
<div>
<h2 id="c3"> References </h2>
<ul>
  [1] A. Tamamori, T. Hayashi, K. Kobayashi, K. Takeda, and T. Toda, “<a href=http://dx.doi.org/10.21437/Interspeech.2017-314>Speaker-dependent WaveNet vocoder</a>,” in Proc. INTERSPEECH, 2017, pp. 1118–1122.
  <br>
  [2] E. Song, K. Byun, and H.-G. Kang, “<a href=https://arxiv.org/abs/1811.04769/>Excitnet vocoder:  A neural excitation model for parametric speech synthesis systems</a>,” in Proc. EUSIPCO, 2019, pp. 1179-1183.
  <br>
</div>


<br>
<hr>
<div>
<h2> Acknowledgements </h2>
<ul> Work performed with nVoice team, Clova Voice, Naver Corp. </ul>  
<br>
</div>

<!--
<hr>
<div>
<h2> Citation </h2>
<ul> 
  <pre><code>@misc{song2018speaker,
    title={Speaker-adaptive neural vocoders for parametric speech synthesis systems},
    author={Song, Eunwoo and Kim, Jinseob and Byun, Kyungguen and Kang, Hong-Goo},
    eprint={1811.03311},
    archivePrefix={arXiv},
    primaryClass={eess.AS},
    year={2018}
  }
  </code></pre>
</ul>  
</div>
<br>
-->

</body>
</html>
